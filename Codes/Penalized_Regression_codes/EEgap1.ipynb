{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  Frisch-Waugh-Lovell and partialling out.\n",
    "This notebook provides an empirical illustration of the Frisch-Waugh-Lovell and partialling out as studied in the course notes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Review of the Frisch-Waugh-Lovell and partialling out.\n",
    "\n",
    " Let us first summarize the main theoretical result.\n",
    "\n",
    "We consider the following equation:\n",
    "$$\n",
    "\\begin{align}\n",
    "Y &= X^\\top\\beta + U =  D^\\top\\beta_1 + W^\\top\\beta_2 + U, \\quad \\operatorname{E}(XU) = 0\n",
    "\\end{align}\n",
    "$$\n",
    "Where $Y$ is the outcome/dependent variable, $X:=(D^\\top, W^\\top)^\\top)$ is a $(k_1+k_2)\\times 1$ vector of regressors, $\\beta:=(\\beta_1^\\top, \\beta_2^\\top)^\\top$ are parameters. We partition the vector\n",
    "of regressors $X$ into two groups: the $k_1$-dimensional subvector $D$ represents “target” regressors of interest, and $k_2$-dimensional subvector $W$ represents other regressors, sometimes called the controls. For example, in wage gender gap analysis, where $Y$ is wage, $D$ is the gender indicator, and $W$ are various other variables explaining variation in wages. In program evaluation, $D$ is often a treatment or policy variable and $W$ are controls. $U$ represent unobserved determinants of $Y$, i.e, the regression error.\n",
    "\n",
    "In population, define the partialling-out operator with respect to a vector $W$ that takes a\n",
    "random variable $V$ such that $\\operatorname{E}(V^2)<\\infty$  and creates $\\tilde{V}$ according to the rule:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\tilde{V} = V - W^\\top\\gamma_{V, W}, \\quad  \\gamma_{V, W} =\\argmin_{b\\in \\R^{k_2}} \\operatorname{E}\\left((V - W^\\top b)^2\\right).\n",
    "\\end{align*}\n",
    "$$\n",
    "When $V$ is a vector, we interpret the application of the operator as componentwise. The\n",
    "vector $W$ needs to have finite second moment in order for this to be well-defined.\n",
    "\n",
    "A remarkable fact, known as Frisch-Waugh-Lovell (FWL) theorem asserts\n",
    "that $\\beta_1$ is a regression coefficient of $Y$ on $D$ after partialing-out the linear effect of $W$\n",
    "from $Y$ and $D$. In other words, it measures linearly the predictive effect (PE) of $D$ on\n",
    "$Y$ , after taking out the linear predictive effect of $W$ on both of these variables:\n",
    "\n",
    "\\begin{align*}\n",
    "\\beta_1 &= \\argmin_{b\\in \\R^{k_1}} \\operatorname{E}\\left((\\tilde{Y} - \\tilde{D}^\\top b)^2\\right) = \n",
    "\\left(\\operatorname{E}(\\tilde{D}\\tilde{D}^\\top)\\right)^{-1}\\operatorname{E}(\\tilde{D}\\tilde{Y}).\n",
    "\\end{align*}\n",
    "\n",
    "In the sample, partialling-out operation works similarly. Define it as an operator that\n",
    "converts $V_i$ into $\\check{V}_i$ via\n",
    "\n",
    "\\begin{align*}\n",
    "\\check{V}_i &= V_i - W_i^\\top\\hat{\\gamma}_{V, W}, \\quad \\hat{\\gamma}_{V, W} = \\argmin_{b\\in \\R^{k_2}}\\operatorname{E}n\\left(V-W^\\top b)^2\\right).\n",
    "\\end{align*}\n",
    "\n",
    "assuming that we have a sample of $n$ i.i.d. copies $\\{(V_i, W_i^\\top)\\}_{i=1}^n$ of $(V, W^\\top)$.\n",
    "\n",
    "Similarly to the population case, we have the sample version of the FWL Theorem:\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{\\beta}_1 = \\argmin_{b\\in \\R^{k_1}} \\operatorname{E}_n\\left((\\check{Y} - \\check{D}^\\top b)^2\\right) = \\left(\\operatorname{E}_n( \\check{D} \\check{D}^\\top)\\right)^{-1}\\operatorname{E}_n( \\check{D} \\check{Y}),\n",
    "\\end{align*}\n",
    "\n",
    "where the notion $\\operatorname{E}_n\\left( f(W) \\right)$ abbreviates the\n",
    "empirical expectation of $f(W)$ as $W$ ranges over the sample $(W_i)_{i=1}^n$:\n",
    "\\begin{align*}\n",
    "\\operatorname{E}_n\\left( f(W) \\right)&= n^{-1}\\sum_{i=1}^n f(W_i),\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application to the gender wage gap in France.\n",
    "\n",
    "### Data Description\n",
    "\n",
    "We consider an empirical application to gender wage gap using data from the French Enployment Survey in 2012. The subsample used in the analysis concerns employed individuals, men and women. We drop observations with missing values for at least one of the variables used in the analysis(outcome and regressors). \n",
    "\n",
    "Specifically the variable of interest $Y$ is the logarithm of the hourly wage rate constructed as the ratio of the annual earnings(SALRED) to the total number of hours worked(NBHEUR). The \"target\" regressor of interest $D$ is an indicator for female worker. The vector of controls $W$ consist of the following variables: indicators/dummies for the marital status(MATRI), for education(DDIPL), occupation(CSER), seniority(ANCENTR4), industry(NAFG4N), region(REG). We also include all the two-way interactions between the these variables. Finally, a quartic in potential experience constructed as\n",
    "the age in 2012 minus the age at the end of schooling minus. More details are provided in the code in the next cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm \n",
    "from sklearn import (\n",
    "    linear_model, metrics, neural_network, pipeline, preprocessing, model_selection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31045 entries, 0 to 31044\n",
      "Columns: 801 entries, Unnamed: 0 to regzus941\n",
      "dtypes: float64(401), int64(358), object(42)\n",
      "memory usage: 189.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#url='https://drive.google.com/file/d/0B6GhBwm5vaB2ekdlZW5WZnppb28/view?usp=sharing'\n",
    "#url='https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
    "#ee12_extract = pd.read_csv(url)\n",
    "#ee12_extract.info()\n",
    "ee12_extract = pd.read_csv('/Users/michalurdanivia/Library/CloudStorage/GoogleDrive-mw.urdanivia@gmail.com/Mon Drive/eemploi2012extract/eemploi2012_s0.csv', low_memory=False)\n",
    "ee12_extract.info()\n",
    "# Les données sont ici: \n",
    "# https://drive.google.com/drive/folders/1qluzqqon8_sF9B0RJ1eqRIqUld0xbBW6?usp=sharing\n",
    "# Les télécharger est changer l'emplacement dans le code ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the path to the file \"eemploi2012_s0.csv\" if needed.\n",
    "eemploi = pd.read_csv('/Users/michalurdanivia/Documents/Bibliothèque/Recherche/Temp/Papiers_etc/eemploitemp/eemploi2012_s0.csv', low_memory=False) \n",
    "eemploi.shape # dimensions du fichiers: nombre de lignes/observations x nombre de colonnes/variables.\n",
    "eemploi = eemploi[['ACTEU', 'SEXE', 'DDIPL', 'FORDAT', 'MATRI', 'TYPMEN5', 'ZUS', 'REG','AG', \n",
    "             'AGQ', 'AGEQ','AGE','AG5','NBENF3', 'NBENF6', 'NBENF18', 'SALRED', 'NBHEUR', \n",
    "             'NATPERC','NATMERC', 'PAIPERC','PAIMERC','TRIM', 'RGI', 'IDENT', 'NOI', \n",
    "             'DIP', 'DIP11','CONTRA','CSER', 'CSPM', 'CSPP', 'ANNEE', 'CHPUB', 'NAFG4N', \n",
    "             'ANCENTR4', 'exper', 'adfe', 'lsalhor']]\n",
    "\n",
    "# Information on the variables selected from the extract(see the dictionary).\n",
    "eemploi.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample selection and additional variables.\n",
    "We select a sample according to the criteria indicated above and define some additional variables, in \n",
    "particular log hourly wage, potential experience, and dummies/indicators for categorical variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We consider the subsample of employed individuals.\n",
    "df = eemploi[(eemploi.ACTEU == 1) & (eemploi.NAFG4N !='00') & (eemploi.CSER !=0)]\n",
    "\n",
    "# We drop observations with missing values.\n",
    "df = df.dropna()\n",
    "\n",
    "# Log-Hourly wage.\n",
    "df['lsal'] = np.log(df['SALRED']/df['NBHEUR'])\n",
    "\n",
    "# Age at the end of schooling.\n",
    "df['afe'] = df['FORDAT'] - (2012 - df['AG'])\n",
    "\n",
    "# Approximate measure of experience in labor market.\n",
    "df['exp'] = df['AG'] - df['afe']\n",
    "\n",
    "# Dummies for categorical variables.\n",
    "# These will not be used when building the design matrix of regressors from the patsy library(see below)\n",
    "dummies = df[['DDIPL', 'MATRI', 'REG', 'ZUS', 'CSER', 'NAFG4N', 'ANCENTR4', 'SEXE']]\n",
    "dummies = pd.get_dummies(data = dummies, columns=['DDIPL', 'MATRI', 'REG', 'ZUS', 'CSER', 'NAFG4N', 'ANCENTR4', 'SEXE'])\n",
    "df = pd.concat([df, dummies], axis = 1)\n",
    "\n",
    "# Some descriptive statistics for the variables used in the analysis.\n",
    "# We first define a list with the hourly wage and potential experience and the dummies(hence \n",
    "# we use the dummies for computing frequencies for categorical variables).\n",
    "listvar = ['lsal', 'exp'] + list(dummies)\n",
    "df[listvar].describe()\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wages, gender, education, occupation.\n",
    "We now look into how (mean)wage is split across groups defined by gender, education, occupation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsal_tab = df.groupby([\"DDIPL\", \"SEXE\", \"CSER\"])['lsal'].mean().unstack(level=\"SEXE\")\n",
    "lsal_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del(dummies, listvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression analysis\n",
    "\n",
    "We first estimate the linear regression model by OLS of $Y$ on $D$ with and without the vector of controls $W$. We then obtains the same estimate using the Frisch-Waugh-Lovell theorem for partialing-out the controls\n",
    "via OLS. Finally we obtain the coefficient of $D$ using a variant of this procedure in\n",
    "that partials-out the controls via LASSO instead of OLS. The Lasso estimator is a high dimensional regression method of particular interest for applications where the number of regressors is potentially bigger than the number of observations. Here we use this method in the (first step) regression of $D$ and $Y$ on $W$ in order to select the most predictive regressors. The lasso will be studied later in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the \"patsy\" library for building the design matrix of regressors from an \"R-type\" formula.\n",
    "import patsy\n",
    "formula = \"\"\"\n",
    "lsal ~ SEXE_2\n",
    "       + (C(DDIPL) + C(ANCENTR4) + C(NAFG4N) + C(REG) + C(CSER) + C(MATRI))**2 \n",
    "       + exp + I(exp**2) + I(exp**3) + I(exp**4)      \n",
    "\"\"\"\n",
    "Y, X = patsy.dmatrices(formula, df, return_type = \"dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homoskedastic Standard Errors.\n",
    "# linreg_ols0 = sm.OLS(endog = Y, exog = X, missing = 'drop').fit()\n",
    "# print(linreg_ols0.summary()) \n",
    "\n",
    "# OLS with Robust \"White\" Standard Errors.\n",
    "# Specification without controls.\n",
    "linreg_ols0 = sm.OLS(endog = Y, exog = X[['Intercept','SEXE_2']], missing = 'drop').fit(cov_type='HC0')\n",
    "\n",
    "# Default printing.\n",
    "#print(linreg_ols0.summary())\n",
    "\n",
    "# Specification with controls.\n",
    "linreg_ols1 = sm.OLS(endog = Y, exog = X, missing = 'drop').fit(cov_type='HC0')\n",
    "\n",
    "# Default printing.\n",
    "#print(linreg_ols1.summary())\n",
    "\n",
    "# We use Stargazer for printing the results(coefficients, and standard errors):\n",
    "# only the coefficient for SEXE_2.\n",
    "# See here for examples: https://github.com/mwburke/stargazer/blob/master/examples.ipynb\n",
    "from stargazer.stargazer import Stargazer, LineLocation\n",
    "stargazer = Stargazer([linreg_ols0 , linreg_ols1])\n",
    "stargazer.covariate_order(['SEXE_2'])\n",
    "stargazer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application of Partialling Out/ Frisch-Waugh-Lovell Theorem(0)\n",
    "\n",
    "W = X.drop(columns = ['SEXE_2'])\n",
    "D = df['SEXE_2']\n",
    "Y = df['lsal']\n",
    "\n",
    "# Step 1: \n",
    "# we partial out the regressors/controls for the treatmement/policy variable and for the outcome.\n",
    "Dreg = sm.OLS(endog = D, exog = W, missing = 'drop').fit(cov_type='HC0')\n",
    "Dhat = Dreg.predict()\n",
    "Dres = D - Dhat\n",
    "Yreg = sm.OLS(endog = Y, exog = W, missing = 'drop').fit(cov_type='HC0')\n",
    "Yhat = Yreg.predict()\n",
    "Yres = Y - Yhat\n",
    "\n",
    "# Step 2: \n",
    "# regression of the residuals associated to the regression of the outcome \n",
    "# on the residuals associated to the treatment/policy.\n",
    "Y_partialReg = sm.OLS(endog = Yres, exog = Dres, missing = 'drop').fit(cov_type='HC0')\n",
    "print(Y_partialReg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application of Partialling Out/ Frisch-Waugh-Lovell Theorem(1)\n",
    "# Difference with (0) is that we partial-out the controls via LASSO instead of OLS.\n",
    "\n",
    "# OLS with sklearn: previously made with statsmodels.\n",
    "#lr_model = linear_model.LinearRegression()\n",
    "#lr_model.fit(X1, Y1)\n",
    "\n",
    "# Step 1: Partial out the controls via Lasso with cross-validation.\n",
    "Ylasso_model = linear_model.LassoCV(cv = 5)\n",
    "Ylasso_model.fit(W, Y)\n",
    "Yhat_lasso = Ylasso_model.predict(W)\n",
    "Yres_lasso = Y - Yhat_lasso\n",
    "Dlasso_model = linear_model.LassoCV(cv = 5)\n",
    "Dlasso_model.fit(W, D)\n",
    "Dhat_lasso = Dlasso_model.predict(W)\n",
    "Dres_lasso = D - Dhat_lasso\n",
    "\n",
    "# Step 2: OLS.\n",
    "Y_partialReg_lasso = sm.OLS(endog = Yres_lasso, exog = Dres_lasso, missing = 'drop').fit(cov_type='HC0')\n",
    "print(Y_partialReg_lasso.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mplc\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_datareader import DataReader\n",
    "\n",
    "%matplotlib inline\n",
    "# activate plot theme\n",
    "import qeds\n",
    "qeds.themes.mpl_style();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_scatter_plot(df, DDIPL, sexe, ax, color):\n",
    "    \"\"\"\n",
    "    This function creates a single year's and education level's\n",
    "    log density to log wage plot\n",
    "    \"\"\"\n",
    "    # Filter data to keep only the data of interest\n",
    "    _df = df.query(\"(DDIPL == @DDIPL) & (SEXE == @sexe)\")\n",
    "    _df.plot(\n",
    "        kind=\"scatter\", x=\"exp\", y=\"lsal\", ax=ax, color=color\n",
    "    )\n",
    "\n",
    "    return ax\n",
    "\n",
    "# Create initial plot\n",
    "fig, ax = plt.subplots(1, 6, figsize=(16, 6), sharey=True)\n",
    "\n",
    "for i in [1, 3, 4, 5, 6, 7]:\n",
    "    single_scatter_plot(df, DDIPL, 1, ax[i], \"b\")\n",
    "    single_scatter_plot(df, DDIPL, 2, ax[i], \"r\")\n",
    "    ax[i].set_title(str(DDIPL))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"https://datascience.quantecon.org/assets/data/density_wage_data.csv\")\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "8a894924a8054982a5c897c02f36d019274ceaf42c853aa8fb1f2ffcb169480b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
